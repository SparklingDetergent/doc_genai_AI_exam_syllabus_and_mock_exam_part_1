# AI試験 模擬試験 - 10. AI倫理・AIガバナンス

**問題1:**

AI倫理に関する国内外のガイドラインで共通して議論される事項として、適切でないものはどれか。

ア) プライバシーの保護
イ) AIモデルの学習速度の最大化
ウ) 公平性と差別禁止
エ) 透明性と説明責任

**問題2:**

AIにおけるプライバシー問題について、データ収集段階と推論段階の双方で問題が生じうるとされている。推論段階でのプライバシー問題の例として、最も適切なものはどれか。

ア) 個人情報を本人の同意なく収集し、AIモデルの学習に利用する。
イ) AIモデルの出力から、学習データに含まれていた特定の個人の情報が推測できてしまう。
ウ) 監視カメラの映像をAIで解析し、個人の行動を追跡する。
エ) 匿名化が不十分なデータを学習に用いてしまう。

**問題3:**

総務省が公表している「カメラ画像利活用ガイドブック」の趣旨として、最も適切なものはどれか。

ア) カメラ画像のAI解析技術の向上を目的とした技術仕様書。
イ) カメラ画像の利活用におけるプライバシーや肖像権への配慮、関係者との合意形成の重要性などを示すもの。
ウ) 高性能な監視カメラの導入を推進するための補助金制度の案内。
エ) カメラ画像のデータ形式や保存期間に関する法的な強制力を持つ規制。

**問題4:**

AIにおける「アルゴリズムバイアス」に関する説明として、最も適切なものはどれか。

ア) AIモデルが学習データに含まれる偏りを反映し、特定のグループに対して不公平な結果を出力する現象。
イ) AIアルゴリズムの計算効率が悪く、処理に時間がかかってしまう問題。
ウ) AIモデルが複雑すぎて、人間にはその動作原理を理解できない状態。
エ) 悪意のある第三者がAIシステムに不正アクセスし、アルゴリズムを改ざんすること。

**問題5:**

アルゴリズムバイアスが生じる原因として、適切でないものはどれか。

ア) 学習データにおける特定の属性（性別、人種など）の偏り。
イ) 社会に既存する差別や偏見がデータに反映されていること。
ウ) モデルの設計者が意図的に特定のグループを優遇または冷遇するような設計を行うこと。
エ) モデルの学習に使用するコンピュータの処理速度が十分に速いこと。

**問題6:**

AI技術の悪用例である「ディープフェイク」とは何か、最も適切な説明はどれか。

ア) AIを用いて、実在しない人物の顔画像を大量に生成する技術。
イ) AIを用いて、既存の画像や動画に写っている人物の顔を別の人物の顔と入れ替えたり、実際には言っていないことを言っているかのように加工したりする技術。
ウ) AIを用いて、オンライン広告のクリック率を不正に操作する技術。
エ) AIを用いて、株価の予測モデルを不正に操作し、市場を混乱させる技術。

**問題7:**

AIと環境保護に関する議論点として、シラバスで言及されている内容に合致するものはどれか。

ア) AIの導入による省エネルギー化が進み、環境負荷は常に低減される。
イ) 大規模なAIモデルの学習には大量の電力消費が伴う一方で、AIは気候変動の予測や対策にも活用されうる。
ウ) AI技術の発展は、環境問題とは全く関連性がない。
エ) 環境保護団体は、AI技術の利用に一貫して反対している。

**問題8:**

AIガバナンスの取り組みの一つである「AI倫理アセスメント」の主な目的として、最も適切なものはどれか。

ア) AIシステムの開発コストを見積もること。
イ) AIシステムが倫理的・法的・社会的な問題を引き起こすリスクを事前に評価し、対策を講じること。
ウ) AIシステムのアルゴリズムの特許申請を行うこと。
エ) AIシステムに関わる全ての従業員の倫理観を統一すること。
