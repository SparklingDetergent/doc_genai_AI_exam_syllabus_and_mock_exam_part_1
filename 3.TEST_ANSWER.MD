# AI試験 模擬試験 - 3. 機械学習の概要 (解答と解説)

### 問題1:
機械学習とルールベース手法の比較に関する記述として、最も適切なものはどれか。

ア) ルールベース手法は大量のデータが必要だが、機械学習は少量のデータでも高い性能を発揮する。
イ) 機械学習は人間が明示的にルールを定義するのに対し、ルールベース手法はデータから自動的にルールを学習する。
ウ) ルールベース手法は解釈性が高いが、複雑なパターンや未知の状況への対応が難しい場合があり、機械学習はそのような状況に対応できる可能性がある。
エ) 機械学習は常にルールベース手法よりも高い精度を達成できる。

**解答:** ウ

**解説:**
機械学習とルールベースは、AIを実現するための異なるアプローチです。

*   **ウ) ルールベース手法は解釈性が高いが、複雑なパターンや未知の状況への対応が難しい場合があり、機械学習はそのような状況に対応できる可能性がある。:** これが最も適切な比較です。
    *   **ルールベース手法:** 人間が「もしAならばBする」というようなルールをたくさん作って、それに基づいてAIを動かします。例えば、チャットボットで「『ありがとう』と言われたら『どういたしまして』と返す」というルールを作るようなものです。ルールが明確なので、なぜAIがそのような判断をしたのか理解しやすい（解釈性が高い）という利点があります。しかし、人間が全てのルールを事前に想定するのは難しく、ルールにない複雑な状況や新しいパターンには対応しにくいという欠点があります。
    *   **機械学習:** 大量のデータの中からAI自身がルールやパターンを見つけ出します。例えば、たくさんの猫の画像を見せて「これが猫だ」と学習させると、新しい画像を見ても猫かどうかを判断できるようになります。人間が明示的に「耳が2つあって、ヒゲがあって…」というルールを教える必要はありません。そのため、人間が気づかないような複雑なパターンを発見したり、未知のデータにもある程度対応できたりする可能性があります。

*   **ア) ルールベース手法は大量のデータが必要だが、機械学習は少量のデータでも高い性能を発揮する。:** 逆です。一般的に、機械学習（特に深層学習）は性能を出すために大量のデータを必要とすることが多いです。ルールベースは、極端な話、データがなくても人間がルールを作れれば動きます。
*   **イ) 機械学習は人間が明示的にルールを定義するのに対し、ルールベース手法はデータから自動的にルールを学習する。:** これも逆の説明です。
*   **エ) 機械学習は常にルールベース手法よりも高い精度を達成できる。:** 「常に」とは限りません。問題の性質やデータの量・質によっては、うまく設計されたルールベースの方が良い性能を出すこともあります。例えば、ルールが非常に明確で変化しないような単純な問題では、ルールベースの方が効率的な場合があります。

どちらの手法が良いかは、解きたい問題の特性や利用できるデータによって異なります。

### 問題2:
以下のうち、教師あり学習のタスクに該当しないものはどれか。

ア) 過去の販売実績データから、将来の売上を予測する。
イ) 顧客の属性データや購買履歴から、特定の商品を購入するかどうかを予測する。
ウ) 大量の顧客データから、類似した嗜好を持つ顧客グループを自動的に発見する。
エ) 手書きの数字画像データと正解ラベルを用いて、新しい手書き数字を認識するモデルを学習する。

**解答:** ウ

**解説:**
機械学習は、学習データの種類によって大きく「教師あり学習」「教師なし学習」「強化学習」に分けられます。

*   **教師あり学習:** AIに「問題（入力データ）」と「正解（出力データ/ラベル）」のペアをたくさん与えて学習させる方法です。AIは、問題と正解の関係性を学び、新しい問題に対しても正解を予測できるようになることを目指します。
    *   **ア) 過去の販売実績データから、将来の売上を予測する。:** 「過去の販売実績（問題）」と「実際の売上（正解）」で学習し、「将来の売上」を予測します。これは回帰問題と呼ばれる教師あり学習です。
    *   **イ) 顧客の属性データや購買履歴から、特定の商品を購入するかどうかを予測する。:** 「顧客データ（問題）」と「購入した/しなかった（正解ラベル）」で学習し、「購入するかどうか」を予測します。これは分類問題と呼ばれる教師あり学習です。
    *   **エ) 手書きの数字画像データと正解ラベルを用いて、新しい手書き数字を認識するモデルを学習する。:** 「手書き数字の画像（問題）」と「その数字が何か（正解ラベル、例：'7'）」で学習し、新しい画像を認識します。これも分類問題です。

*   **教師なし学習:** AIに「正解」を与えず、データそのものの構造やパターンを見つけ出させる方法です。
    *   **ウ) 大量の顧客データから、類似した嗜好を持つ顧客グループを自動的に発見する。:** これは教師なし学習の代表例である「クラスタリング」です。AIはデータの特徴に基づいて、似たもの同士をグループ分けします。事前に「この顧客はこのグループ」という正解はありません。例えば、購買傾向が似ている顧客をいくつかのグループに分けることで、それぞれのグループに合ったマーケティング戦略を立てるのに役立ちます。

したがって、教師あり学習に該当しないものは「ウ」です。

### 問題3:
「単回帰分析」と「重回帰分析」の主な違いとして、最も適切なものはどれか。

ア) 単回帰分析は分類問題に用いられ、重回帰分析は回帰問題に用いられる。
イ) 単回帰分析は説明変数が一つであるのに対し、重回帰分析は複数の説明変数を用いる。
ウ) 単回帰分析は線形関係のみを扱えるのに対し、重回帰分析は非線形関係も扱える。
エ) 単回帰分析は教師なし学習であり、重回帰分析は教師あり学習である。

**解答:** イ

**解説:**
回帰分析は、ある変数（目的変数）の値を、別の変数（説明変数）の値を使って予測する統計的手法です。

*   **イ) 単回帰分析は説明変数が一つであるのに対し、重回帰分析は複数の説明変数を用いる。:** これが単回帰分析と重回帰分析の最も本質的な違いです。
    *   **単回帰分析:** 1つの説明変数で目的変数を予測します。例えば、「部屋の広さ（説明変数）」だけで「家賃（目的変数）」を予測するような場合です。グラフで表現すると、横軸に部屋の広さ、縦軸に家賃をプロットし、その関係を一本の直線で表そうとします。
    *   **重回帰分析:** 複数の説明変数で目的変数を予測します。例えば、「部屋の広さ」「駅からの距離」「築年数」（これら全てが説明変数）を使って「家賃（目的変数）」を予測するような場合です。より多くの情報を考慮するため、単回帰分析よりも複雑な関係性を捉え、より精度の高い予測が期待できることがあります。

*   **ア) 単回帰分析は分類問題に用いられ、重回帰分析は回帰問題に用いられる。:** 両方とも回帰問題（連続的な数値を予測する問題）に用いられます。分類問題（カテゴリを予測する問題、例：合格/不合格）とは異なります。
*   **ウ) 単回帰分析は線形関係のみを扱えるのに対し、重回帰分析は非線形関係も扱える。:** 基本的な単回帰分析・重回帰分析は線形関係（変数が変化すると、もう一方の変数も一定の割合で変化する関係）を仮定しますが、工夫次第で非線形関係を扱うことも可能です（例：変数を2乗した項を加えるなど）。この選択肢は、主な違いとは言えません。
*   **エ) 単回帰分析は教師なし学習であり、重回帰分析は教師あり学習である。:** 両方とも教師あり学習です。目的変数が「正解」の役割を果たします。

簡単に言えば、「説明に使う材料が1種類なら単回帰、2種類以上なら重回帰」と覚えると良いでしょう。

### 問題4:
レコメンデーションエンジンにおける「コールドスタート問題」とは何か、最も適切な説明はどれか。

ア) システムの計算負荷が高すぎて、推奨アイテムの算出に時間がかかりすぎる問題。
イ) 新規ユーザーや新規アイテムのように、評価データが不足しているために適切な推奨が困難になる問題。
ウ) 推奨されるアイテムが多様性に欠け、ユーザーが飽きてしまう問題。
エ) ユーザーの嗜好が時間とともに変化し、過去のデータに基づく推奨が的外れになる問題。

**解答:** イ

**解説:**
コールドスタート問題は、レコメンデーションシステム（おすすめ機能）が直面する代表的な課題の一つです。

*   **イ) 新規ユーザーや新規アイテムのように、評価データが不足しているために適切な推奨が困難になる問題。:** これがコールドスタート問題の正しい説明です。「コールドスタート」とは、エンジンが冷え切った状態から始動することを指し、データが十分に温まっていない（蓄積されていない）状態を比喩しています。
    *   **新規ユーザーの場合:** システムに登録したばかりのユーザーは、まだ何のアイテムも評価（購入、閲覧、いいねなど）していないため、そのユーザーの好みが分からず、何を推奨して良いか困ってしまいます。
    *   **新規アイテムの場合:** 新しく追加された商品は、まだ誰からも評価されていないため、どのようなユーザーに推奨すべきか判断できません。

*   **ア) システムの計算負荷が高すぎて、推奨アイテムの算出に時間がかかりすぎる問題。:** これはスケーラビリティや計算効率の問題であり、コールドスタート問題とは異なります。
*   **ウ) 推奨されるアイテムが多様性に欠け、ユーザーが飽きてしまう問題。:** これはセレンディピティ（偶然の素敵な発見）の欠如やフィルターバブルといった問題に関連しますが、コールドスタート問題とは直接的な意味合いが異なります。
*   **エ) ユーザーの嗜好が時間とともに変化し、過去のデータに基づく推奨が的外れになる問題。:** これはコンセプトドリフトや嗜好の変化への追従といった問題であり、コールドスタート問題とは異なります。

コールドスタート問題を緩和するためには、ユーザーに初期の好みをいくつか尋ねたり（コンテンツベースフィルタリングの活用）、人気商品をとりあえず推奨したりするなどの対策が取られます。

### 問題5:
機械学習モデルの評価において、「混同行列」が示す情報として適切でないものはどれか。

ア) 真陽性 (True Positive) の数
イ) モデルの学習にかかった時間
ウ) 偽陽性 (False Positive) の数
エ) 偽陰性 (False Negative) の数

**解答:** イ

**解説:**
混同行列（Confusion Matrix）は、主に分類モデルの性能を評価するために使われる表です。モデルがどれだけ正しく分類できたか、そしてどのように間違えたかを詳細に示します。

*   混同行列は、実際のクラスとモデルの予測クラスを比較し、以下の4つのカテゴリに分類します。
    *   **ア) 真陽性 (True Positive, TP):** 実際に「陽性」のものを、正しく「陽性」と予測した数。例：病気の検査で、本当に病気の人を「病気です」と正しく診断した。
    *   **ウ) 偽陽性 (False Positive, FP):** 実際は「陰性」なのに、誤って「陽性」と予測した数。例：健康な人を「病気です」と誤診した。（Type I エラー、αエラーとも呼ばれます）
    *   **エ) 偽陰性 (False Negative, FN):** 実際は「陽性」なのに、誤って「陰性」と予測した数。例：病気の人を「健康です」と誤診した。（Type II エラー、βエラーとも呼ばれます）
    *   **真陰性 (True Negative, TN):** 実際に「陰性」のものを、正しく「陰性」と予測した数。例：健康な人を「健康です」と正しく診断した。

*   **イ) モデルの学習にかかった時間:** これはモデルの計算効率に関する情報であり、混同行列自体が直接示すものではありません。混同行列は、あくまで「予測結果の正誤パターン」を表すものです。

混同行列を見ることで、モデルがどのような間違いをしやすいのか（例えば、病気を見逃しやすいのか、それとも健康な人を病気と間違えやすいのか）を把握でき、適合率や再現率といった他の評価指標を計算する基礎にもなります。

### 問題6:
モデルの「過学習（Overfitting）」に関する説明として、最も適切なものはどれか。

ア) 訓練データに対しては高い性能を示すが、未知のデータ（テストデータ）に対しては性能が低い状態。
イ) 訓練データに対しても、未知のデータに対しても性能が低い状態。
ウ) モデルが単純すぎて、データが持つ複雑なパターンを捉えきれていない状態。
エ) 学習が進むにつれて、訓練誤差と汎化誤差の両方が減少していく状態。

**解答:** ア

**解説:**
過学習（Overfitting、過剰適合とも）は、機械学習モデルを訓練する際によく発生する問題です。

*   **ア) 訓練データに対しては高い性能を示すが、未知のデータ（テストデータ）に対しては性能が低い状態。:** これが過学習の正しい説明です。モデルが訓練データに「適合しすぎ」てしまい、訓練データに含まれるノイズや偶発的な特徴まで学習してしまった結果、新しい未知のデータに対してはうまく対応できなくなってしまう現象です。
    *   例：テスト勉強で、練習問題の答えを丸暗記してしまった生徒が、練習問題では満点を取れるけれど、少し問題の形式が変わった本番のテストでは全く点数が取れない、という状況に似ています。練習問題（訓練データ）に特化しすぎて、応用力（汎化性能）がなくなってしまった状態です。

*   **イ) 訓練データに対しても、未知のデータに対しても性能が低い状態。:** これは「未学習（Underfitting）」と呼ばれる状態に近いか、あるいはモデルの性能が単純に低い状態です。
*   **ウ) モデルが単純すぎて、データが持つ複雑なパターンを捉えきれていない状態。:** これが「未学習（Underfitting）」の説明です。モデルがデータの傾向を十分に学習できていない状態です。
*   **エ) 学習が進むにつれて、訓練誤差と汎化誤差の両方が減少していく状態。:** これは理想的な学習が進んでいる状態を示しており、過学習ではありません。過学習の場合、訓練誤差は減少し続けますが、ある時点から汎化誤差（テストデータに対する誤差）は逆に増加し始めます。

過学習を防ぐためには、訓練データを増やす、モデルを単純にする（正則化など）、早期終了（Early Stopping）などのテクニックが用いられます。

### 問題7:
「交差検証（Cross-validation）」の主な目的として、最も適切なものはどれか。

ア) モデルの学習速度を向上させること。
イ) より少ないデータでモデルを学習させること。
ウ) モデルの汎化性能をより頑健に評価すること。
エ) モデルの解釈性を高めること。

**解答:** ウ

**解説:**
交差検証（Cross-validation、クロスバリデーション）は、機械学習モデルの性能を客観的に評価するための重要な手法です。

*   **ウ) モデルの汎化性能をより頑健に評価すること。:** これが交差検証の主な目的です。「汎化性能」とは、モデルが学習に使わなかった未知のデータに対して、どれだけ正しく予測できるかという能力のことです。
    *   **なぜ必要か？** 通常、手元にあるデータを訓練用とテスト用に分けてモデルを評価しますが、たまたまテストデータがモデルにとって「得意な」問題ばかりだったり、「苦手な」問題ばかりだったりする可能性があります。そうなると、その一度きりのテスト結果だけでは、モデルの真の性能を正しく評価できたとは言えません。
    *   **交差検証の仕組み（k-分割交差検証の場合）：** データをk個のグループに分割します。そのうちの1グループをテスト用、残りのk-1グループを訓練用としてモデルを学習・評価します。これを、テスト用にするグループを順番に変えながらk回繰り返します。そして、k回分の評価結果の平均を取ることで、特定のデータ分割に依存しない、より信頼性の高い汎化性能の評価が得られます。
    *   例：5分割交差検証なら、データを5つに分け、それぞれ1回ずつテストデータとして使い、計5回モデルの学習と評価を行います。これにより、データ全体を評価に使うことができ、評価の偏りを減らせます。

*   **ア) モデルの学習速度を向上させること。:** 交差検証は評価の手法であり、学習速度を直接向上させるものではありません。むしろ、複数回学習を行うため、全体の時間はかかる傾向にあります。
*   **イ) より少ないデータでモデルを学習させること。:** データが少ない場合に特に有効な評価方法ではありますが、学習自体をより少ないデータで行うための技術ではありません。
*   **エ) モデルの解釈性を高めること。:** モデルの解釈性を高める手法（XAIなど）とは直接的な関係はありません。

交差検証は、モデルの性能を「より公平に」「より信頼できる形で」測るためのものさし、と考えると良いでしょう。

### 問題8:
ある病気の検査について、適合率（Precision）と再現率（Recall）を評価指標として用いる場合、特に再現率を重視すべき状況はどれか。

ア) 検査のコストが高く、陽性と判定された人にのみ精密検査を行う場合。
イ) 病気を見逃すことの社会的・個人的コストが非常に高く、偽陰性をできるだけ減らしたい場合。
ウ) 健常者を誤って陽性と判定することの不利益が非常に大きい場合。
エ) 検査対象者の数が非常に多く、迅速な検査結果が求められる場合。

**解答:** イ

**解説:**
適合率と再現率は、特に二値分類（例：陽性/陰性、合格/不合格）のモデル評価でよく使われる指標で、トレードオフの関係にあることが多いです。

*   **適合率 (Precision):** 「陽性と予測したもののうち、実際に陽性だったものの割合」。つまり、「AIが『これは陽性だ！』と自信を持って言った予測が、どれだけ当たっていたか」を示します。
    *   計算式: `適合率 = 真陽性 / (真陽性 + 偽陽性)`
    *   適合率を重視する例：迷惑メールフィルタ。迷惑メールでないメールを迷惑メールと判定してしまう（偽陽性）とユーザーが困るので、迷惑メールと判定したものは本当に迷惑メールである確率を高めたい（適合率を高くしたい）。

*   **再現率 (Recall):** 「実際に陽性だったもののうち、正しく陽性と予測できたものの割合」。つまり、「本当に陽性のものを、どれだけ見逃さずに捕まえられたか」を示します。
    *   計算式: `再現率 = 真陽性 / (真陽性 + 偽陰性)`
    *   再現率を重視する例：重篤な病気の検査。病気の人を見逃してしまう（偽陰性）と命に関わるので、多少健康な人を誤診してしまう（偽陽性）としても、病気の人をできるだけ多く見つけ出したい（再現率を高くしたい）。

*   **イ) 病気を見逃すことの社会的・個人的コストが非常に高く、偽陰性をできるだけ減らしたい場合。:** この状況では、再現率を重視すべきです。偽陰性（本当は病気なのに見逃す）を減らすことが最優先されるためです。
    *   例：がん検診。がんの患者さんを見逃してしまうと、手遅れになる可能性があります。そのため、少しでも疑わしければ「陽性（要精密検査）」として、見逃しを減らすことが重要になります。

*   **ア) 検査のコストが高く、陽性と判定された人にのみ精密検査を行う場合。:** この場合は、むやみに陽性と判定して精密検査のコストを増やしたくないため、適合率を重視する傾向があります。「陽性と判定された人は、本当に陽性である可能性が高い」状態を目指します。
*   **ウ) 健常者を誤って陽性と判定することの不利益が非常に大きい場合。:** これも適合率を重視する状況です。偽陽性を減らしたいというニーズです。
*   **エ) 検査対象者の数が非常に多く、迅速な検査結果が求められる場合。:** これは主に処理速度やスループットの問題であり、適合率や再現率のどちらを重視すべきかとは直接結びつきません。

どちらの指標を重視するかは、そのAIモデルがどのような目的で使われ、どのような間違いがより深刻な結果を招くかによって決まります。多くの場合、両者のバランスを取ったF値（F-measure）という指標も用いられます。
