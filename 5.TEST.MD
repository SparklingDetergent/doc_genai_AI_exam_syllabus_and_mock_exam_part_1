# AI試験 模擬試験 - 5. ディープラーニングの要素技術

**問題1:**

畳み込みニューラルネットワーク (CNN) における「カーネル（フィルタ）」の主な役割として、最も適切なものはどれか。

ア) 入力データから特定の特徴（エッジ、テクスチャなど）を抽出する。
イ) 入力データの次元を削減し、計算量を減らす。
ウ) 活性化関数として機能し、非線形性を導入する。
エ) 出力層でクラスの確率を計算する。

**問題2:**

CNNにおける「ストライド」の説明として、最も適切なものはどれか。

ア) 入力画像の外周に追加されるピクセルの幅。
イ) カーネルが一度に移動するピクセル数。
ウ) プーリング層で縮小される領域のサイズ。
エ) 畳み込み層の出力チャネル数。

**問題3:**

プーリング層の主な目的として、適切でないものはどれか。

ア) 入力データに対する位置の微小なずれに対して頑健性を持たせる（不変性の獲得）。
イ) 特徴マップの次元を削減し、計算コストを低減する。
ウ) ネットワークのパラメータ数を大幅に増やすことで、表現力を向上させる。
エ) 過学習を抑制する効果が期待できる場合がある。

**問題4:**

ResNetで導入された「スキップ結合（ショートカット接続）」が主に解決しようとした問題は何か。

ア) 畳み込み処理の計算コストが高い問題。
イ) ネットワークの層が深くなることによる勾配消失問題や性能劣化。
ウ) プーリング層による情報損失の問題。
エ) 活性化関数の選択が難しい問題。

**問題5:**

リカレントニューラルネットワーク (RNN) が特に適しているデータの種類は何か。

ア) 画像データのようなグリッド構造を持つデータ。
イ) 顧客の属性データのようなテーブル形式のデータ。
ウ) 音声やテキストのような時系列データやシーケンシャルデータ。
エ) 特徴間の関係性が複雑な高次元の疎なデータ。

**問題6:**

LSTM (Long Short-Term Memory) や GRU (Gated Recurrent Unit) が、単純なRNNと比較して改善した主な点は何か。

ア) 計算速度を大幅に向上させた。
イ) より少ないデータで学習できるようになった。
ウ) 長期的な依存関係を学習しやすくなり、勾配消失問題を緩和した。
エ) あらゆる種類のデータに対応できるようになった。

**問題7:**

Transformerモデルで中心的な役割を果たす「Attention機構」に関する説明として、最も適切なものはどれか。

ア) 入力シーケンスの各要素に対して、均等な重みを割り当てることで情報を集約する。
イ) 出力を生成する際に、入力シーケンスの特定の部分に注目し、関連性の高い情報に大きな重みを割り当てる。
ウ) ネットワークの層をスキップすることで、情報の伝達を効率化する。
エ) 畳み込み演算を用いて、局所的な特徴を抽出する。

**問題8:**

データ拡張 (Data Augmentation) の主な目的として、最も適切なものはどれか。

ア) 学習データの量を擬似的に増やし、モデルの過学習を抑制して汎化性能を向上させる。
イ) 学習データのノイズを除去し、クリーンなデータセットを作成する。
ウ) 学習データの次元を削減し、計算効率を高める。
エ) モデルの解釈性を向上させるために、重要な特徴を強調する。
