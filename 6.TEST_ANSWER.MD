# AI試験 模擬試験 - 6. ディープラーニングの応用例 (解答と解説)

### 問題1:
大規模言語モデル (LLM) に関する記述として、最も適切なものはどれか。

ア) 主に画像認識タスクのために設計された小規模なニューラルネットワークである。
イ) 大量のテキストデータで事前学習され、人間のような自然なテキストを生成したり、理解したりする能力を持つ。
ウ) 強化学習のみを用いて学習され、特定のゲームを攻略する能力に特化している。
エ) 音声認識と音声合成を組み合わせることで、リアルタイムの翻訳を行う。

**解答:** イ

**解説:**
大規模言語モデル (LLM: Large Language Model) は、近年のAI技術の中でも特に注目を集めている分野です。

*   **イ) 大量のテキストデータで事前学習され、人間のような自然なテキストを生成したり、理解したりする能力を持つ。:** これがLLMの最も適切な説明です。LLMは、インターネット上のウェブページや書籍など、膨大な量のテキストデータを学習することで、人間が使う言葉のパターンや文法、さらには文脈に応じた意味の理解や生成能力を獲得します。代表的なものにOpenAIのGPTシリーズやGoogleのBERT、LaMDAなどがあります。
    *   例：人間がたくさんの本を読んで言葉を覚えるように、LLMも大量の文章を読むことで、「この単語の次にはこの単語が来やすい」「この質問にはこう答えるのが自然だ」といったことを学習します。これにより、質問応答、文章作成、翻訳、要約など、様々な言語関連タスクに対応できます。

*   **ア) 主に画像認識タスクのために設計された小規模なニューラルネットワークである。:** LLMは主にテキストデータを扱い、その名の通り「大規模」なニューラルネットワーク（数億～数兆ものパラメータを持つことも）です。画像認識はCNNなどが得意とする分野です。
*   **ウ) 強化学習のみを用いて学習され、特定のゲームを攻略する能力に特化している。:** LLMの学習は主に自己教師あり学習（テキストデータそのものから学習信号を作り出す）で行われますが、特定のタスクへの適応（ファインチューニング）や、より人間にとって有用な応答を生成するために強化学習（人間のフィードバックからの強化学習：RLHF）が用いられることもあります。しかし、「強化学習のみ」ではなく、またゲーム攻略に特化しているわけでもありません。
*   **エ) 音声認識と音声合成を組み合わせることで、リアルタイムの翻訳を行う。:** 音声認識や音声合成もAIの重要な技術ですが、LLMの核となる機能はテキストの理解と生成です。翻訳システムではLLMが中心的な役割を果たすことがありますが、音声の入出力は別の技術との組み合わせになります。

LLMは、その汎用性の高さから「基盤モデル (Foundation Model)」とも呼ばれ、様々な応用が期待されています。

### 問題2:
Diffusion Model (拡散モデル) が近年注目されている主な応用分野は何か。

ア) 表形式データの回帰分析
イ) 高品質な画像や音声などのデータ生成
ウ) 時系列データの異常検知
エ) ソフトウェアのバグ検出

**解答:** イ

**解説:**
Diffusion Model（拡散モデル）は、特に高品質なデータを生成する能力で注目を集めている比較的新しい生成モデルの一種です。

*   **イ) 高品質な画像や音声などのデータ生成:** これがDiffusion Modelの主な応用分野です。Diffusion Modelは、元データに徐々にノイズを加えていき、最終的に完全なノイズにしてしまう過程（拡散過程）と、その逆の過程（逆拡散過程または生成過程）を学習します。学習後は、ランダムなノイズからスタートして、徐々にノイズを除去していくことで、元のデータ分布に近い新しいデータを生成できます。
    *   例：きれいな絵に少しずつ霧をかけていき、最後は真っ白な霧だけにする（拡散過程）。次に、その霧を少しずつ晴らしていくと、元の絵が現れる（生成過程）。Diffusion Modelはこの「霧を晴らす」方法を学習し、全く新しい絵を霧から作り出すことができる、というイメージです。Stable DiffusionやDALL-E 2（一部）などが有名な画像生成AIで、この技術を応用しています。

*   **ア) 表形式データの回帰分析:** 回帰分析は、連続値を予測するタスクであり、Diffusion Modelの主な応用分野ではありません。
*   **ウ) 時系列データの異常検知:** 時系列データの異常検知にはRNNやTransformerなどが用いられることがありますが、Diffusion Modelの主要な応用先とは言えません（研究レベルでは試みがあるかもしれません）。
*   **エ) ソフトウェアのバグ検出:** ソフトウェア工学のタスクであり、現在のDiffusion Modelの主な応用分野ではありません。

Diffusion Modelは、従来の生成モデル（GANなど）と比較して、学習が安定しやすく、かつ非常に高品質で多様なデータを生成できるポテンシャルを持つため、画像生成、音声合成、動画生成など、様々なクリエイティブな分野での活用が期待されています。

### 問題3:
「Zero-shot Learning」の説明として、最も適切なものはどれか。

ア) 学習データに全く含まれていない新しいクラスのサンプルに対しても、ある程度の識別や理解ができる学習手法。
イ) 非常に少数の学習サンプルだけを用いて、新しいタスクに対応する学習手法。
ウ) 複数の異なるモダリティのデータ（例：画像とテキスト）を同時に処理し、理解する学習手法。
エ) モデルのパラメータ数をゼロに近づけることで、極めて軽量なモデルを作成する手法。

**解答:** ア

**解説:**
Zero-shot Learning (ZSL) は、機械学習モデルが学習時に一度も見たことのないクラス（カテゴリ）のデータを、テスト時になんとか認識しようとする野心的な学習パラダイムです。

*   **ア) 学習データに全く含まれていない新しいクラスのサンプルに対しても、ある程度の識別や理解ができる学習手法。:** これがZero-shot Learningの正しい説明です。通常の教師あり学習では、学習時に見たクラスしか認識できません。ZSLでは、クラス名やクラスの属性情報（例えば、「シマウマ」というクラスを学習していなくても、「馬に似ている」「縞模様がある」といった属性情報を学習しておくことで、初めてシマウマの画像を見ても、それがシマウマである可能性が高いと推論する）などを手がかりにして、未知のクラスを認識しようとします。
    *   例：子供が「パンダ」という動物を写真や絵で見たことがなくても、「白と黒の模様で、熊に似ていて、竹を食べる動物だよ」と教えておけば、動物園で初めてパンダを見たときに「あれがパンダかな？」と推測できるかもしれません。これに似たことをAIにさせようとするのがZSLです。

*   **イ) 非常に少数の学習サンプルだけを用いて、新しいタスクに対応する学習手法。:** これは「Few-shot Learning (FSL)」の説明です。ZSLは「ゼロショット」なので、未知クラスの学習サンプルは一つもありません。
*   **ウ) 複数の異なるモダリティのデータ（例：画像とテキスト）を同時に処理し、理解する学習手法。:** これは「マルチモーダル学習」の説明です。ZSLで属性情報としてテキスト記述を使うなど、マルチモーダルな情報が活用されることはありますが、ZSLの定義そのものではありません。
*   **エ) モデルのパラメータ数をゼロに近づけることで、極めて軽量なモデルを作成する手法。:** これはモデル圧縮や軽量化の文脈で使われる言葉（例：スパースモデリング）であり、ZSLとは異なります。

Zero-shot Learningは、AIがより人間のように柔軟な認識能力を獲得するための重要な研究分野です。

### 問題4:
「転移学習 (Transfer Learning)」の主な利点として、適切でないものはどれか。

ア) あるタスクで学習した知識を別の関連タスクに活用することで、学習に必要なデータ量を削減できる。
イ) 大規模なデータセットで事前学習されたモデルを利用することで、学習時間を短縮できる。
ウ) ターゲットタスクにおけるモデルの性能向上が期待できる。
エ) あらゆるタスクにおいて、常にゼロから学習するよりも高い性能を保証する。

**解答:** エ

**解説:**
転移学習は、ある領域やタスクで学習したモデルの知識を、別の（しかし関連のある）領域やタスクに「転移」させて再利用する機械学習の手法です。

*   **ア) あるタスクで学習した知識を別の関連タスクに活用することで、学習に必要なデータ量を削減できる。:** これは転移学習の大きな利点の一つです。例えば、大量の一般的な画像で学習した画像認識モデル（事前学習済みモデル）の知識を、特定の専門的な画像（例：医療画像、特定の製品の画像）の認識タスクに転用する場合、専門的な画像の学習データが少量しかなくても、比較的良い性能が得られることがあります。
*   **イ) 大規模なデータセットで事前学習されたモデルを利用することで、学習時間を短縮できる。:** これも利点です。事前学習済みモデルは既に多くの基本的な特徴（画像の線や形、テキストの単語の意味など）を学習しているので、新しいタスクではそれらの知識を再利用し、より少ない時間で学習を収束させることができます。
*   **ウ) ターゲットタスクにおけるモデルの性能向上が期待できる。:** これも重要な利点です。特にターゲットタスクのデータが少ない場合、ゼロから学習するよりも、関連する大規模データで事前学習された知識を活用することで、より高い汎化性能が得られることが期待できます。

*   **エ) あらゆるタスクにおいて、常にゼロから学習するよりも高い性能を保証する。:** これが適切でない記述です。「常に保証する」わけではありません。転移学習が効果を発揮するためには、事前学習タスクとターゲットタスクがある程度関連している必要があります。全く関連性のないタスク間で知識を転移しようとすると、かえって性能が悪化する「負の転移」が起こることもあります。また、ターゲットタスクのデータが非常に大量かつ質が高い場合は、ゼロから学習した方が良い結果が得られる可能性も否定できません。

転移学習は、AI開発の効率化と性能向上に大きく貢献する実用的なテクニックですが、万能薬ではないことを理解しておく必要があります。

### 問題5:
モデルの解釈性 (XAI: Explainable AI) が重要視される理由として、最も適切なものはどれか。

ア) モデルの予測精度を最大化するため。
イ) モデルの学習に必要な計算コストを削減するため。
ウ) モデルの判断根拠を人間が理解できるようにし、信頼性や透明性を確保するため。
エ) モデルのアーキテクチャを自動的に最適化するため。

**解答:** ウ

**解説:**
XAI (Explainable AI、説明可能なAI) は、AIの判断プロセスや根拠を人間が理解できるようにするための技術や考え方です。

*   **ウ) モデルの判断根拠を人間が理解できるようにし、信頼性や透明性を確保するため。:** これがXAIが重要視される最も大きな理由です。特にディープラーニングのような複雑なモデルは、なぜそのような予測や判断をしたのかが内部的に非常に分かりにくく、「ブラックボックス」と批判されることがあります。XAIは、このブラックボックスの内部を可視化したり、判断に至った理由を人間が理解できる形で示したりすることで、以下のようなことを目指します。
    *   **信頼性の向上:** AIの判断根拠が分かれば、その判断が妥当かどうかを人間が検証でき、AIを信頼して使えるようになります。
    *   **公平性の担保:** AIが特定の属性（性別、人種など）に基づいて不公平な判断をしていないかを確認できます。
    *   **安全性の確保:** 特に医療や自動運転など、人命に関わる分野では、AIの誤判断が重大な結果を招く可能性があるため、判断根拠の理解が不可欠です。
    *   **デバッグや改善:** AIが間違った判断をした場合に、その原因を特定し、モデルを改善するのに役立ちます。
    *   **法的・倫理的責任:** AIの判断によって問題が生じた場合、その責任の所在を明らかにするためにも説明可能性が求められます。

*   **ア) モデルの予測精度を最大化するため。:** XAIの主目的は精度向上ではありません。むしろ、解釈性を高めるためにモデルの複雑さをある程度犠牲にしたり、解釈のための追加的な処理が必要になったりすることもあります。
*   **イ) モデルの学習に必要な計算コストを削減するため。:** XAI技術の導入は、むしろ追加の計算コストを伴う場合があります。
*   **エ) モデルのアーキテクチャを自動的に最適化するため。:** これはニューラルアーキテクチャサーチ (NAS) などの分野のテーマであり、XAIとは異なります。

AIが社会の様々な場面で使われるようになるにつれて、その判断の透明性や説明責任がますます重要になっており、XAIの研究と実用化が進められています。

### 問題6:
モデルの軽量化技術の一つである「量子化 (Quantization)」とは、どのような手法か。

ア) モデルの重要でない接続を削除（プルーニング）することで、パラメータ数を削減する手法。
イ) 大きなモデル（教師モデル）の知識を、より小さなモデル（生徒モデル）に転移させる手法。
ウ) モデルの重みや活性化関数を、より少ないビット数の数値表現に変換することで、モデルサイズと計算量を削減する手法。
エ) 複数の異なるモデルの予測を組み合わせることで、単一モデルよりも高い性能を得る手法。

**解答:** ウ

**解説:**
モデルの軽量化は、AIモデルをスマートフォンやエッジデバイスのようなリソースが限られた環境で動作させるために重要な技術です。量子化はその代表的な手法の一つです。

*   **ウ) モデルの重みや活性化関数を、より少ないビット数の数値表現に変換することで、モデルサイズと計算量を削減する手法。:** これが量子化の正しい説明です。通常、ニューラルネットワークの重みや活性化関数の値は、32ビット浮動小数点数のような比較的精度の高い数値で表現されます。量子化では、これらの数値を、例えば8ビット整数やさらに少ないビット数の固定小数点数などに変換します。
    *   **モデルサイズの削減:** 1つの数値を表現するのに必要なビット数が減るため、モデル全体のファイルサイズが小さくなります。
    *   **計算量の削減:** 低ビットの数値演算は、高ビットの浮動小数点演算よりも高速に行えるハードウェアが多いため、推論速度が向上します。また、消費電力も削減できる場合があります。
    *   例：アナログの体重計（連続的な値）の目盛りを、1kg刻みのデジタル表示（離散的な値）にするようなイメージです。多少の精度は犠牲になるかもしれませんが、表示がシンプルになり、扱いやすくなります。

*   **ア) モデルの重要でない接続を削除（プルーニング）することで、パラメータ数を削減する手法。:** これは「プルーニング（枝刈り）」という別の軽量化技術です。
*   **イ) 大きなモデル（教師モデル）の知識を、より小さなモデル（生徒モデル）に転移させる手法。:** これは「知識蒸留（Knowledge Distillation）」という別の軽量化・性能向上技術です。
*   **エ) 複数の異なるモデルの予測を組み合わせることで、単一モデルよりも高い性能を得る手法。:** これは「アンサンブル学習」という性能向上技術です。

量子化は、モデルの精度をできるだけ維持しつつ、モデルサイズと計算量を削減することを目指しますが、一般的には多少の精度低下が伴うことがあります。そのバランスをどう取るかが重要になります。

### 問題7:
「マルチモーダルAI」が扱うデータの例として、最も適切なものはどれか。

ア) 大量の英語のテキストデータのみ。
イ) 様々な犬種の画像データのみ。
ウ) 画像とその画像内容を説明するテキストのペアデータ。
エ) 金融市場の株価の時系列データのみ。

**解答:** ウ

**解説:**
マルチモーダルAIは、複数の異なる種類（モダリティ）の情報を同時に扱って処理するAIのことです。

*   **ウ) 画像とその画像内容を説明するテキストのペアデータ。:** これがマルチモーダルAIが扱うデータの典型的な例です。「画像」という視覚情報モダリティと、「テキスト」という言語情報モダリティを組み合わせて扱います。
    *   例：ある犬の画像（画像モダリティ）と、「公園で楽しそうにボールを追いかけるゴールデンレトリバー」（テキストモダリティ）というキャプションがペアになっているデータセットを学習することで、AIは画像の内容を理解したり、逆にテキストから画像を生成したりする能力を獲得できます。画像キャプション生成、テキストからの画像生成、視覚的な質問応答（VQA）などがマルチモーダルAIの応用例です。

*   **ア) 大量の英語のテキストデータのみ。:** これは単一モダリティ（テキスト）のデータです。
*   **イ) 様々な犬種の画像データのみ。:** これも単一モダリティ（画像）のデータです。
*   **エ) 金融市場の株価の時系列データのみ。:** これも単一モダリティ（時系列数値）のデータです。

人間は、目で見たり、耳で聞いたり、言葉を話したりと、常に複数のモダリティの情報を統合して世界を認識し、コミュニケーションを取っています。マルチモーダルAIは、そのような人間の情報処理能力に近づこうとする試みであり、より豊かで深い理解をAIに持たせることを目指しています。音声と映像を組み合わせた動画理解などもマルチモーダルAIの範疇です。

### 問題8:
深層強化学習が応用されている事例として、適切なものはどれか。

ア) 大量の顧客データに基づいたクレジットスコアリング。
イ) 医療画像からの腫瘍の自動検出。
ウ) 複雑なゲーム（囲碁やビデオゲームなど）における人間レベル、あるいはそれ以上のプレイスキルの獲得。
エ) 顧客のレビューテキストの感情分析。

**解答:** ウ

**解説:**
深層強化学習 (Deep Reinforcement Learning, DRL) は、ディープラーニング（深層学習）と強化学習を組み合わせた技術です。エージェント（行動主体）が試行錯誤を通じて、ある環境において報酬を最大化するような行動方針（戦略）を学習します。

*   **ウ) 複雑なゲーム（囲碁やビデオゲームなど）における人間レベル、あるいはそれ以上のプレイスキルの獲得。:** これが深層強化学習の代表的な応用事例です。AlphaGoが囲碁でトッププロ棋士を破った事例や、AlphaStarがStarCraft IIで高いパフォーマンスを示した事例、OpenAI FiveがDota 2でプロチームと互角に戦った事例などが有名です。これらのゲームでは、盤面やゲーム画面という高次元の入力（これをディープラーニングで処理する）に対して、エージェントが行動を選択し、その結果得られる報酬（勝利やスコアなど）を最大化するように学習が進められます。
    *   例：ロボットが迷路を脱出するタスクで、最初はランダムに動き回りますが、ゴールに到達すると「報酬」が与えられます。この報酬をより多く得られるように、ロボットは「壁にぶつからないように進む」「以前通った道筋を参考にする」といった行動を学習していきます。深層学習は、この「壁」や「道筋」といった状況をロボットのセンサー情報（カメラ画像など）から認識するのに役立ちます。

*   **ア) 大量の顧客データに基づいたクレジットスコアリング。:** これは主に教師あり学習（分類問題）の応用例です。過去の顧客データとデフォルト履歴（正解ラベル）から学習します。
*   **イ) 医療画像からの腫瘍の自動検出。:** これも主に教師あり学習（画像分類や物体検出）の応用例です。医師がアノテーションした画像データから学習します。
*   **エ) 顧客のレビューテキストの感情分析。:** これも主に教師あり学習（テキスト分類）の応用例です。ポジティブ/ネガティブなどの感情ラベルが付与されたテキストデータから学習します。

深層強化学習は、ゲーム以外にも、ロボット制御（例：複雑なマニピュレーション）、自動運転の意思決定、資源配分の最適化など、明確な教師データがない状況で、試行錯誤を通じて最適な戦略を見つけ出す必要がある問題への応用が期待されています。
